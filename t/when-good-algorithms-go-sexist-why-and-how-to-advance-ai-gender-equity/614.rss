<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>When Good Algorithms Go Sexist: Why and How to Advance AI Gender Equity</title>
    <link>https://forum.openglobalmind.com/t/when-good-algorithms-go-sexist-why-and-how-to-advance-ai-gender-equity/614</link>
    <description>## Seven actions social change leaders and machine learning developers can take to build gender-smart artificial intelligence for a more just world.

&quot;In 2019, Genevieve (co-author of this article) and her husband applied for the same credit card. Despite having a slightly better credit score and the same income, expenses, and debt as her husband, the credit card company set her credit limit at almost half the amount. This experience echoes one [that made headlines](https://www.nytimes.com/2019/11/10/business/Apple-credit-card-investigation.html) later that year: A husband and wife compared their Apple Card spending limits and found that the husband’s credit line was 20 times greater. Customer service employees were unable to explain why the algorithm deemed the wife significantly less creditworthy.

Many institutions make decisions based on artificial intelligence (AI) systems using machine learning (ML), whereby a series of algorithms takes and learns from massive amounts of data to find patterns and make predictions. These systems inform how much credit financial institutions offer different customers, who the health care system prioritizes for COVID-19 vaccines, and which candidates companies call in for job interviews. Yet gender bias in these systems is pervasive and has profound impacts on women’s short- and long-term psychological, economic, and health security. It can also reinforce and amplify existing harmful gender stereotypes and prejudices.

As we conclude Women&#39;s History Month, social change leaders—including researchers and professionals with gender expertise—and ML systems developers alike need to ask: How can we build gender-smart AI to advance gender equity, rather than embed and scale gender bias?&quot;

https://ssir.org/articles/entry/when_good_algorithms_go_sexist_why_and_how_to_advance_ai_gender_equity</description>
    
    <lastBuildDate>Fri, 02 Apr 2021 01:23:31 +0000</lastBuildDate>
    <category>Uncategorized</category>
    <atom:link href="https://forum.openglobalmind.com/t/when-good-algorithms-go-sexist-why-and-how-to-advance-ai-gender-equity/614.rss" rel="self" type="application/rss+xml" />
      <item>
        <title>When Good Algorithms Go Sexist: Why and How to Advance AI Gender Equity</title>
        <dc:creator><![CDATA[kenhomer]]></dc:creator>
        <description><![CDATA[
            <h2>Seven actions social change leaders and machine learning developers can take to build gender-smart artificial intelligence for a more just world.</h2>
<p>"In 2019, Genevieve (co-author of this article) and her husband applied for the same credit card. Despite having a slightly better credit score and the same income, expenses, and debt as her husband, the credit card company set her credit limit at almost half the amount. This experience echoes one <a href="https://www.nytimes.com/2019/11/10/business/Apple-credit-card-investigation.html" rel="nofollow noopener">that made headlines</a> later that year: A husband and wife compared their Apple Card spending limits and found that the husband’s credit line was 20 times greater. Customer service employees were unable to explain why the algorithm deemed the wife significantly less creditworthy.</p>
<p>Many institutions make decisions based on artificial intelligence (AI) systems using machine learning (ML), whereby a series of algorithms takes and learns from massive amounts of data to find patterns and make predictions. These systems inform how much credit financial institutions offer different customers, who the health care system prioritizes for COVID-19 vaccines, and which candidates companies call in for job interviews. Yet gender bias in these systems is pervasive and has profound impacts on women’s short- and long-term psychological, economic, and health security. It can also reinforce and amplify existing harmful gender stereotypes and prejudices.</p>
<p>As we conclude Women’s History Month, social change leaders—including researchers and professionals with gender expertise—and ML systems developers alike need to ask: How can we build gender-smart AI to advance gender equity, rather than embed and scale gender bias?"</p>
<p><a href="https://ssir.org/articles/entry/when_good_algorithms_go_sexist_why_and_how_to_advance_ai_gender_equity" class="onebox" target="_blank" rel="nofollow noopener">https://ssir.org/articles/entry/when_good_algorithms_go_sexist_why_and_how_to_advance_ai_gender_equity</a></p>
          <p><a href="https://forum.openglobalmind.com/t/when-good-algorithms-go-sexist-why-and-how-to-advance-ai-gender-equity/614/1">Read full topic</a></p>
        ]]></description>
        <link>https://forum.openglobalmind.com/t/when-good-algorithms-go-sexist-why-and-how-to-advance-ai-gender-equity/614/1</link>
        <pubDate>Fri, 02 Apr 2021 01:23:31 +0000</pubDate>
        <guid isPermaLink="false">forum.openglobalmind.com-post-614-1</guid>
        <source url="https://forum.openglobalmind.com/t/when-good-algorithms-go-sexist-why-and-how-to-advance-ai-gender-equity/614.rss">When Good Algorithms Go Sexist: Why and How to Advance AI Gender Equity</source>
      </item>
  </channel>
</rss>
