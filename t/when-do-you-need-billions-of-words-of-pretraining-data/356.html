<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <title>&quot;When Do You Need Billions of Words of Pretraining Data - Tools - Open Global Mind Forum</title>
    <meta name="description" content="See more at:">
    <meta name="generator" content="Discourse 2.6.0.beta1 - https://github.com/discourse/discourse version fc63f0d316210545ddf1e59441472fd33da31154">
<link rel="icon" type="image/png" href="../../uploads/default/optimized/1x/6ad26af246303315f5448e572bb5671ffc7f08a0_2_32x32.ico">
<link rel="apple-touch-icon" type="image/png" href="../../uploads/default/optimized/1x/e9becd07f4ea852a2b914bd5ca6c82a23ea04c67_2_180x180.png">
<meta name="theme-color" content="#ffffff">
<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, user-scalable=yes, viewport-fit=cover">
<link rel="canonical" href="356.html" />
<script type="application/ld+json">{"@context":"http://schema.org","@type":"WebSite","url":"https://forum.openglobalmind.com","potentialAction":{"@type":"SearchAction","target":"https://forum.openglobalmind.com/search?q={search_term_string}","query-input":"required name=search_term_string"}}</script>
<link rel="search" type="application/opensearchdescription+xml" href="../../opensearch.xml" title="Open Global Mind Forum Search">

      <link href="https://forum.openglobalmind.com/stylesheets/desktop_c093910115d9aa0ef4d8915bfa850aed166ee06b.css?__ws=forum.openglobalmind.com" media="all" rel="stylesheet" data-target="desktop" data-theme-id="2"/>
      <link href="https://forum.openglobalmind.com/stylesheets/desktop_theme_2_5bf3f204dc8788bc237ac5f7b3988ebf4bc7b6ab.css?__ws=forum.openglobalmind.com" media="all" rel="stylesheet" data-target="desktop_theme" data-theme-id="2"/>
    
    
        <link rel="alternate" type="application/rss+xml" title="RSS feed of &#39;&quot;When Do You Need Billions of Words of Pretraining Data&#39;" href="356.rss" />
    <meta property="og:site_name" content="Open Global Mind Forum" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:image" content="https://forum.openglobalmind.com/uploads/default/original/1X/e9becd07f4ea852a2b914bd5ca6c82a23ea04c67.png" />
<meta property="og:image" content="https://forum.openglobalmind.com/uploads/default/original/1X/e9becd07f4ea852a2b914bd5ca6c82a23ea04c67.png" />
<meta property="og:url" content="https://forum.openglobalmind.com/t/when-do-you-need-billions-of-words-of-pretraining-data/356" />
<meta name="twitter:url" content="https://forum.openglobalmind.com/t/when-do-you-need-billions-of-words-of-pretraining-data/356" />
<meta property="og:title" content="&quot;When Do You Need Billions of Words of Pretraining Data" />
<meta name="twitter:title" content="&quot;When Do You Need Billions of Words of Pretraining Data" />
<meta property="og:description" content="See more at:" />
<meta name="twitter:description" content="See more at:" />
<meta name="twitter:label1" value="Reading time" />
<meta name="twitter:data1" value="1 mins 🕑" />
<meta name="twitter:label2" value="Likes" />
<meta name="twitter:data2" value="1 ❤" />
<meta property="article:published_time" content="2020-11-12T14:42:52+00:00" />
<meta property="og:ignore_canonical" content="true" />



    
  </head>
  <body class="crawler">
    
    <header style="position:static; z-index:auto">
      <a href="https://forum.openglobalmind.com/">
          <img src="../../uploads/default/original/1x/d6338ab7a8595161a7b7be3a1fbfb9ce25dd773d.png" alt="Open Global Mind Forum" id="site-logo" style="max-width: 150px;">
      </a>
    <p>Note: OGM Forum is no longer active. This is a static snapshot as of February 2022. You can browse the site to see posts, but the functional features of the site will not work. You can search or download a zip archive of the files from the site at <a href="https://github.com/OpenGlobalMind/forum.openglobalmind.com">github/OpenGlobalMind/forum.openglobalmind.com</a>.</p></header>
    <div id="main-outlet" class="wrap">
        <div id="topic-title">
    <h1>
      <a href="356.html">&quot;When Do You Need Billions of Words of Pretraining Data</a>
    </h1>

      <div class="topic-category" itemscope itemtype="http://schema.org/BreadcrumbList">
          <span itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
            <a href="https://forum.openglobalmind.com/c/designing-the-system/9" class="badge-wrapper bullet" itemprop="item">
              <span class='badge-category-bg' style='background-color: #ED207B'></span>
              <span class='badge-category clear-badge'>
                <span class='category-name' itemprop='name'>Designing the System</span>
              </span>
            </a>
            <meta itemprop="position" content="1" />
          </span>
          <span itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
            <a href="https://forum.openglobalmind.com/c/designing-the-system/tools/10" class="badge-wrapper bullet" itemprop="item">
              <span class='badge-category-bg' style='background-color: #ED207B'></span>
              <span class='badge-category clear-badge'>
                <span class='category-name' itemprop='name'>Tools</span>
              </span>
            </a>
            <meta itemprop="position" content="2" />
          </span>
      </div>

      <div class="topic-category">
        <div class='discourse-tags list-tags'>
            <a href='../../tag/machine-learning.html' class='discourse-tag' rel="tag">machine-learning</a>
        </div>
      </div>
  </div>

  


      <div itemscope itemtype='http://schema.org/DiscussionForumPosting' class='topic-body crawler-post'>
        <div class='crawler-post-meta'>
          <div itemprop='publisher' itemscope itemtype="http://schema.org/Organization">
            <meta itemprop='name' content='Open Global Mind Forum'>
              <div itemprop='logo' itemscope itemtype="http://schema.org/ImageObject">
                <meta itemprop='url' content='https://forum.openglobalmind.com/uploads/default/original/1X/d6338ab7a8595161a7b7be3a1fbfb9ce25dd773d.png'>
              </div>
          </div>
          <span class="creator" itemprop="author" itemscope itemtype="http://schema.org/Person">
            <a itemprop="url" href='../../u/peterkaminski.html'><span itemprop='name'>peterkaminski</span></a>
            
          </span>

          <link itemprop="mainEntityOfPage" href="356.html">


          <span class="crawler-post-infos">
              <time itemprop='datePublished' datetime='2020-11-12T14:42:52Z' class='post-time'>
                November 12, 2020,  2:42pm
              </time>
              <meta itemprop='dateModified' content='2020-11-12T14:42:52Z'>
          <span itemprop='position'>#1</span>
          </span>
        </div>
        <div class='post' itemprop='articleBody'>
          <p>See more at:</p>
<aside class="onebox twitterstatus">
  <header class="source">
      <a href="https://twitter.com/zhang_yian/status/1325836454975557632" target="_blank" rel="noopener">twitter.com</a>
  <p>Note: OGM Forum is no longer active. This is a static snapshot as of February 2022. You can browse the site to see posts, but the functional features of the site will not work. You can search or download a zip archive of the files from the site at <a href="https://github.com/OpenGlobalMind/forum.openglobalmind.com">github/OpenGlobalMind/forum.openglobalmind.com</a>.</p></header>
  <article class="onebox-body">
    <img src="../../uploads/default/optimized/1x/0ba7a23d0ba67031dfd31e7a74d358674bb029e7_2_690x456.jpeg" class="thumbnail onebox-avatar" width="690" height="456" srcset="../../uploads/default/optimized/1x/0ba7a23d0ba67031dfd31e7a74d358674bb029e7_2_690x456.jpeg, ../../uploads/default/optimized/1x/0ba7a23d0ba67031dfd31e7a74d358674bb029e7_2_1035x684.jpeg 1.5x, ../../uploads/default/original/1x/0ba7a23d0ba67031dfd31e7a74d358674bb029e7.jpeg 2x" data-small-upload="https://forum.openglobalmind.com/uploads/default/optimized/1X/0ba7a23d0ba67031dfd31e7a74d358674bb029e7_2_10x10.png">

<h4><a href="https://twitter.com/zhang_yian/status/1325836454975557632" target="_blank" rel="noopener">Yian Zhang (zhang_yian)</a></h4>

<div class="tweet"> 🚨 NEW PAPER ALERT 🤓 CURVES📈📈📈 ALERT 🚨
Transformer LMs pretrained on billions of words have dominated NLP, but which skills/features really depend on this huge scale? How much can models learn from more modest amounts of data?  [1/10]</div>

<div class="date">
  <a href="https://twitter.com/zhang_yian/status/1325836454975557632" target="_blank" rel="noopener">8:23 AM - 9 Nov 2020</a>
    <span class="like">
      <svg viewBox="0 0 512 512" width="14px" height="16px" aria-hidden="true">
        <path d="M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z"></path>
      </svg> 210
    </span>
    <span class="retweet">
      <svg viewBox="0 0 640 512" width="14px" height="16px" aria-hidden="true">
        <path d="M629.657 343.598L528.971 444.284c-9.373 9.372-24.568 9.372-33.941 0L394.343 343.598c-9.373-9.373-9.373-24.569 0-33.941l10.823-10.823c9.562-9.562 25.133-9.34 34.419.492L480 342.118V160H292.451a24.005 24.005 0 0 1-16.971-7.029l-16-16C244.361 121.851 255.069 96 276.451 96H520c13.255 0 24 10.745 24 24v222.118l40.416-42.792c9.285-9.831 24.856-10.054 34.419-.492l10.823 10.823c9.372 9.372 9.372 24.569-.001 33.941zm-265.138 15.431A23.999 23.999 0 0 0 347.548 352H160V169.881l40.416 42.792c9.286 9.831 24.856 10.054 34.419.491l10.822-10.822c9.373-9.373 9.373-24.569 0-33.941L144.971 67.716c-9.373-9.373-24.569-9.373-33.941 0L10.343 168.402c-9.373 9.373-9.373 24.569 0 33.941l10.822 10.822c9.562 9.562 25.133 9.34 34.419-.491L96 169.881V392c0 13.255 10.745 24 24 24h243.549c21.382 0 32.09-25.851 16.971-40.971l-16.001-16z"></path>
      </svg> 44
    </span>
</div>

  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>

<aside class="onebox allowlistedgeneric">
  <header class="source">
      <img src="https://github.githubassets.com/favicons/favicon.svg" class="site-icon" width="32" height="32">
      <a href="https://github.com/nyu-mll/pretraining-learning-curves" target="_blank" rel="noopener">GitHub</a>
  <p>Note: OGM Forum is no longer active. This is a static snapshot as of February 2022. You can browse the site to see posts, but the functional features of the site will not work. You can search or download a zip archive of the files from the site at <a href="https://github.com/OpenGlobalMind/forum.openglobalmind.com">github/OpenGlobalMind/forum.openglobalmind.com</a>.</p></header>
  <article class="onebox-body">
    <img src="../../uploads/default/original/1x/2089f9ad15c06e6c951578d2e26638375e29c317.png" class="thumbnail onebox-avatar" width="128" height="128">

<h3><a href="https://github.com/nyu-mll/pretraining-learning-curves" target="_blank" rel="noopener">nyu-mll/pretraining-learning-curves</a></h3>

<p>The repository for the paper "When Do You Need Billions of Words of Pretraining Data?" - nyu-mll/pretraining-learning-curves</p>


  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>

        </div>

        <meta itemprop='headline' content='&quot;When Do You Need Billions of Words of Pretraining Data'>
          <meta itemprop='keywords' content='machine-learning'>

        <div itemprop="interactionStatistic" itemscope itemtype="http://schema.org/InteractionCounter">
           <meta itemprop="interactionType" content="http://schema.org/LikeAction"/>
           <meta itemprop="userInteractionCount" content="1" />
           <span class='post-likes'>1 Like</span>
         </div>

         <div itemprop="interactionStatistic" itemscope itemtype="http://schema.org/InteractionCounter">
            <meta itemprop="interactionType" content="http://schema.org/CommentAction"/>
            <meta itemprop="userInteractionCount" content="0" />
          </div>

      </div>
      <div itemscope itemtype='http://schema.org/DiscussionForumPosting' class='topic-body crawler-post'>
        <div class='crawler-post-meta'>
          <div itemprop='publisher' itemscope itemtype="http://schema.org/Organization">
            <meta itemprop='name' content='Open Global Mind Forum'>
              <div itemprop='logo' itemscope itemtype="http://schema.org/ImageObject">
                <meta itemprop='url' content='https://forum.openglobalmind.com/uploads/default/original/1X/d6338ab7a8595161a7b7be3a1fbfb9ce25dd773d.png'>
              </div>
          </div>
          <span class="creator" itemprop="author" itemscope itemtype="http://schema.org/Person">
            <a itemprop="url" href='../../u/jackpark.html'><span itemprop='name'>jackpark</span></a>
            
          </span>

          <link itemprop="mainEntityOfPage" href="356.html">


          <span class="crawler-post-infos">
              <time itemprop='datePublished' datetime='2020-11-12T22:19:55Z' class='post-time'>
                November 12, 2020, 10:19pm
              </time>
              <meta itemprop='dateModified' content='2020-11-12T22:19:55Z'>
          <span itemprop='position'>#2</span>
          </span>
        </div>
        <div class='post' itemprop='articleBody'>
          <aside class="onebox allowlistedgeneric">
  <header class="source">
      <img src="https://static.arxiv.org/static/browse/0.3.2.6/images/icons/favicon.ico" class="site-icon" width="16" height="16">
      <a href="https://arxiv.org/abs/2011.04946" target="_blank" rel="nofollow noopener">arXiv.org</a>
  <p>Note: OGM Forum is no longer active. This is a static snapshot as of February 2022. You can browse the site to see posts, but the functional features of the site will not work. You can search or download a zip archive of the files from the site at <a href="https://github.com/OpenGlobalMind/forum.openglobalmind.com">github/OpenGlobalMind/forum.openglobalmind.com</a>.</p></header>
  <article class="onebox-body">
    <img src="356.html" class="thumbnail" width="16" height="16">

<h3><a href="https://arxiv.org/abs/2011.04946" target="_blank" rel="nofollow noopener">When Do You Need Billions of Words of Pretraining Data?</a></h3>

<p>NLP is currently dominated by general-purpose pretrained language models like
RoBERTa, which achieve strong performance on NLU tasks through pretraining on
billions of words. But what exact knowledge or skills do Transformer LMs learn
from...</p>


  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>

        </div>

        <meta itemprop='headline' content='&quot;When Do You Need Billions of Words of Pretraining Data'>

        <div itemprop="interactionStatistic" itemscope itemtype="http://schema.org/InteractionCounter">
           <meta itemprop="interactionType" content="http://schema.org/LikeAction"/>
           <meta itemprop="userInteractionCount" content="0" />
           <span class='post-likes'></span>
         </div>

         <div itemprop="interactionStatistic" itemscope itemtype="http://schema.org/InteractionCounter">
            <meta itemprop="interactionType" content="http://schema.org/CommentAction"/>
            <meta itemprop="userInteractionCount" content="1" />
          </div>

      </div>
      <div itemscope itemtype='http://schema.org/DiscussionForumPosting' class='topic-body crawler-post'>
        <div class='crawler-post-meta'>
          <div itemprop='publisher' itemscope itemtype="http://schema.org/Organization">
            <meta itemprop='name' content='Open Global Mind Forum'>
              <div itemprop='logo' itemscope itemtype="http://schema.org/ImageObject">
                <meta itemprop='url' content='https://forum.openglobalmind.com/uploads/default/original/1X/d6338ab7a8595161a7b7be3a1fbfb9ce25dd773d.png'>
              </div>
          </div>
          <span class="creator" itemprop="author" itemscope itemtype="http://schema.org/Person">
            <a itemprop="url" href='../../u/jackpark.html'><span itemprop='name'>jackpark</span></a>
            
          </span>

          <link itemprop="mainEntityOfPage" href="356.html">


          <span class="crawler-post-infos">
              <time itemprop='datePublished' datetime='2020-11-12T22:21:58Z' class='post-time'>
                November 12, 2020, 10:21pm
              </time>
              <meta itemprop='dateModified' content='2020-11-12T22:21:58Z'>
          <span itemprop='position'>#3</span>
          </span>
        </div>
        <div class='post' itemprop='articleBody'>
          <blockquote>
<p>NLP is currently dominated by general-purpose pretrained language models like RoBERTa, which achieve strong performance on NLU tasks through pretraining on billions of words. But what exact knowledge or skills do Transformer LMs learn from large-scale pretraining that they cannot learn from less data? We adopt four probing methods—classifier probing, information-theoretic probing, unsupervised relative acceptability judgment, and fine-tuning on NLU tasks—and draw learning curves that track the growth of these different measures of linguistic ability with respect to pretraining data volume using the MiniBERTas, a group of RoBERTa models pretrained on 1M, 10M, 100M and 1B words. We find that LMs require only about 10M or 100M words to learn representations that reliably encode most syntactic and semantic features we test. A much larger quantity of data is needed in order to acquire enough commonsense knowledge and other skills required to master typical downstream NLU tasks. The results suggest that, while the ability to encode linguistic features is almost certainly necessary for language understanding, it is likely that other forms of knowledge are the major drivers of recent improvements in language understanding among large pretrained models.</p>
</blockquote>
        </div>

        <meta itemprop='headline' content='&quot;When Do You Need Billions of Words of Pretraining Data'>

        <div itemprop="interactionStatistic" itemscope itemtype="http://schema.org/InteractionCounter">
           <meta itemprop="interactionType" content="http://schema.org/LikeAction"/>
           <meta itemprop="userInteractionCount" content="0" />
           <span class='post-likes'></span>
         </div>

         <div itemprop="interactionStatistic" itemscope itemtype="http://schema.org/InteractionCounter">
            <meta itemprop="interactionType" content="http://schema.org/CommentAction"/>
            <meta itemprop="userInteractionCount" content="0" />
          </div>

      </div>






    </div>
    <footer class="container wrap">
      <nav class='crawler-nav'>
        <ul>
        <li itemscope itemtype='http://schema.org/SiteNavigationElement'>
          <span itemprop='name'>
            <a href='https://forum.openglobalmind.com/' itemprop="url">Home </a>
          </span>
        </li>
        <li itemscope itemtype='http://schema.org/SiteNavigationElement'>
          <span itemprop='name'>
            <a href='https://forum.openglobalmind.com/categories' itemprop="url">Categories </a>
          </span>
        </li>
        <li itemscope itemtype='http://schema.org/SiteNavigationElement'>
          <span itemprop='name'>
            <a href='https://forum.openglobalmind.com/guidelines' itemprop="url">FAQ/Guidelines </a>
          </span>
        </li>
        <li itemscope itemtype='http://schema.org/SiteNavigationElement'>
          <span itemprop='name'>
            <a href='https://forum.openglobalmind.com/tos' itemprop="url">Terms of Service </a>
          </span>
        </li>
        <li itemscope itemtype='http://schema.org/SiteNavigationElement'>
          <span itemprop='name'>
            <a href='https://forum.openglobalmind.com/privacy' itemprop="url">Privacy Policy </a>
          </span>
        </li>
        </ul>
      </nav>
      <p class='powered-by-link'>Originally powered by <a href="https://www.discourse.org">Discourse</a>, but no longer interactive.</p>
    </footer>
    
    
  </body>
  
</html>
